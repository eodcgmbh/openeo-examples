{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC2 - Vessel Detection\n",
    "\n",
    "In this notebook we will take a look at how to apply adaptive thresholding to SENTINEL1_GRD data within OpenEO Platform. We will then take a look at our results against ship location data from Maritime Traffic Agency over the Adriatic. We will be using the the openeo-python-client to prepare our process graph, and a Plotly Dash dashboard to interact with our results.\n",
    "\n",
    "### Recap\n",
    "\n",
    "We've been through a number of iterations to arrive at this process graph.\n",
    "\n",
    "1. Recieved an initial implementation from Planetek, which we packaged and released as a custom function, \"vessel_detection\". \n",
    "2. Porting to Xarray only function, a single function called \"adaptive_thresholding\", that removed the dependency to the ellipsoid corrected SENTINEL1_GRD imagery.\n",
    "3. Porting to existing OpenEO processes. This addresses the feedback from the previous review, i.e. the implementation should be reproducable for this use case.\n",
    "\n",
    "These iteration steps roughly describe the process of how we can go about onboarding new processes into the OpenEO Platform.\n",
    "\n",
    "Initial Implementation > Containerise > Reduce Dependencies > Xarray > OpenEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Thresholding in Xarray\n",
    "\n",
    "After investigating the code initially provided by Planetek, we arrived at this xarray implementation of adaptive thresholding.\n",
    "\n",
    "```python\n",
    "WINDOW_LAT_SIZE = 30\n",
    "WINDOW_LON_SIZE = 30\n",
    "THRESHOLD_FACT = 4\n",
    "out = xr.ones_like(data)\n",
    "rolling_mean = data.rolling(\n",
    "    longitude=WINDOW_LAT_SIZE, latitude=WINDOW_LON_SIZE, center=True\n",
    ").mean()\n",
    "thresholded_image = data > rolling_mean * THRESHOLD_FACT\n",
    "raster = out.where(thresholded_image == True, other=0)\n",
    "```\n",
    "\n",
    "We are going to port this into an OpenEO process graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "\n",
    "backend = \"openeo-dev.eodc.eu/openeo/1.1.0/\" # \"openeo.cloud\"\n",
    "conn = openeo.connect(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = conn.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing prep:\n",
    "\n",
    "This process graph requires either a sea or land mask to remove the land from our AOI. A seamask has been prepared for this example and is available on github. It was derived using the [Water Bodies](https://land.copernicus.eu/content/corine-land-cover-nomenclature-guidelines/html/) classes from Corine Land Cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# We are going to use the following GeoJson to operate as a sea mask for out process graph.\n",
    "SEA_MASK = \"https://raw.githubusercontent.com/SerRichard/sea_mask/main/sea-mask-4326.json\"\n",
    "\n",
    "fig = folium.Figure(width=600, height=400)\n",
    "map = folium.Map(location=[44.465488, 12.602316], zoom_start=8)\n",
    "folium.GeoJson(SEA_MASK).add_to(map)\n",
    "fig.add_child(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining a process graph to detect vessels in our AOI.\n",
    "\n",
    "The spatial_extent we have defined includes, but is not limited to the sea mask that we will be using. We will use both available polarizations from the SENTINEL1_GRD collection, and run this graph on a little over a weeks worth of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_extent  = {\n",
    "          \"west\": 12.194377989297493,\n",
    "          \"east\": 12.758093271633888,\n",
    "          \"south\": 44.24420099164355,\n",
    "          \"north\": 44.85455845353388\n",
    "        }\n",
    "\n",
    "temporal_extent = [\n",
    "          \"2021-10-01\",\n",
    "          \"2021-10-09\"\n",
    "        ]\n",
    "\n",
    "collection      = \"SENTINEL1_GRD\"\n",
    "bands           = [\"VV\",\"VH\"]\n",
    "\n",
    "s1_datacube = conn.load_collection(\n",
    "    collection,\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands,\n",
    "    temporal_extent=temporal_extent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the geometries as a vector cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_mask = s1_datacube.process(\"load_vector_cube\", {\"URL\": SEA_MASK})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the values that lie outside of our polygon with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_data = s1_datacube.mask_polygon(sea_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve the equivalent functionality of `data.rolling()`, we will use the process apply_kernel. The kernel will be the length and width of the window we want to apply the convolution to. The value of each pixel in the kernel is equal to `1/(kernel_width*kernel_height)`, spreading the weight evenly will achieve a mean for across the pixels in the kernel. The resut of the convolution is multiplied then multipled in the process by the factor value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_value = 0.00104\n",
    "kernel = [\n",
    "    [\n",
    "      kernel_value for y in range(0, 31)\n",
    "    ] for x in range(0, 31)\n",
    "]\n",
    "\n",
    "applied_kernel = masked_data.apply_kernel(kernel=kernel,factor=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to compare the results of apply_kernel, against the values of the data we initially masked. We can use the process merge_cubes with the overlap resolver set to the less than process to acheive this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_comparison = applied_kernel.merge_cubes(\n",
    "  masked_data, overlap_resolver=\"lt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the resulting boolean datacube to a vector cube, and output the result in save result as a GeoJson. This will make the comparison of our results with the Maritime traffic data more straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = lt_comparison.raster_to_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_detection = output_data.save_result(format=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and trigger the job. We can regularly poll the status to ensure it has finished, before moving on to the visualisation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_vessel_detection = vessel_detection.create_job(title = \"UC2-Vessel-Detection\")\n",
    "job_vessel_detection.start_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_vessel_detection.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_results = job_vessel_detection.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run Auxilliary job\n",
    "\n",
    "You can additionally run the following job, if you would like to compare the original Sentinel1_GRD data, against the results from the vessel detection. This comparison makes it easier to visually validate the results, and spot erroneous polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel1_data = s1_datacube.save_result(format=\"GTiff\")\n",
    "sentinel1_data_job = sentinel1_data.create_job(title = \"UC2-Auxilliary-Job\")\n",
    "sentinel1_data_job.start_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel1_data_job.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_job_results = sentinel1_data_job.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the canonical URL for a given job\n",
    "\n",
    "def canonical_url_from_job(job: openeo.BatchJob):\n",
    "    \"\"\" Helper function to get the canonical URL for a finish batch job. \"\"\"\n",
    "    links = [ link for link in job.get_metadata()['links'] if link['rel'] == \"canonical\" ]\n",
    "    return links[0]['href'] if len(links) != 0 else None\n",
    "\n",
    "canon_url = canonical_url_from_job(job_results)\n",
    "aux_canon_url = canonical_url_from_job(aux_job_results)\n",
    "\n",
    "display(canon_url)\n",
    "display(aux_canon_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualisation\n",
    "\n",
    "We will use a small dashboard created with the Plotly Dash library to quickly visualise the results of our processing. We're using this dashboard so we can interface with the PyGeoApi server that hosts the Maritime Traffic data.\n",
    "\n",
    "PyGeoApi Data: https://features.dev.services.eodc.eu/collections/adriatic_vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eodc.visualisation.vessel_detection.app import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
